{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366d376a-1b9f-4ebc-b5d2-c1696526adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "#from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# qdrant official client\n",
    "import qdrant_client\n",
    "\n",
    "# LLama-index dependencies\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "#from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe6951-00f8-42ab-bf99-b9905664d358",
   "metadata": {},
   "source": [
    "# Document Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ed1b4-1332-4e24-904f-70d7373f79e2",
   "metadata": {},
   "source": [
    "## Extraction using PyMUPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7b72c-2af2-4322-be77-6ca7afffa113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375d49e9-406e-453a-8b1f-88d97559d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import fitz\n",
    "\n",
    "file_path = \"../data/Q1-2023-Amazon-Earnings-Release.pdf\"\n",
    "doc = fitz.open(file_path) #A\n",
    "#B\n",
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=2048,\n",
    ")\n",
    "text_chunks = [] #C\n",
    "for doc_idx, page in enumerate(doc):\n",
    "    page_text = page.get_text(\"text\")\n",
    "    cur_text_chunks = text_parser.split_text(page_text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "nodes = [] #D\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    nodes.append(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3690513-219f-4421-af4a-7059e9b4ca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMAZON.COM, INC.\n",
      "Consolidated Statements of Comprehensive Income (Loss)\n",
      "(in millions)\n",
      "(unaudited)\n",
      "  \n",
      "Three Months Ended\n",
      "March 31,\n",
      " \n",
      "2022\n",
      "2023\n",
      "Net income (loss)\n",
      "$ \n",
      "(3,844) $ \n",
      "3,172 \n",
      "Other comprehensive income (loss):\n",
      "Foreign currency translation adjustments, net of tax of $(16) and $(10)\n",
      " \n",
      "(333)  \n",
      "386 \n",
      "Net change in unrealized gains (losses) on available-for-sale debt securities:\n",
      "Unrealized gains (losses), net of tax of $1 and $(29)\n",
      " \n",
      "(662)  \n",
      "95 \n",
      "Reclassification adjustment for losses (gains) included in “Other income (expense), \n",
      "net,” net of tax of $0 and $(10)\n",
      " \n",
      "6  \n",
      "33 \n",
      "Net unrealized gains (losses) on available-for-sale debt securities\n",
      " \n",
      "(656)  \n",
      "128 \n",
      "Total other comprehensive income (loss)\n",
      " \n",
      "(989)  \n",
      "514 \n",
      "Comprehensive income (loss)\n",
      "$ \n",
      "(4,833) $ \n",
      "3,686\n"
     ]
    }
   ],
   "source": [
    "print(nodes[8].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312d6d6-ae34-4607-ad12-66debdd212f8",
   "metadata": {},
   "source": [
    "## Extraction using LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93968620-7b07-467a-a0d5-389ea2ca94a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ····················································\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42bec72-ba52-4c6a-9c8f-815e77d745cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ···················································\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289be495-a0e9-4899-b7d2-da4404147e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37e2493a-35d1-4ed9-a038-ab061dda83fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cac11eca-0a23-4d2b-9ca3-dc10139cf738\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "documents = LlamaParse(result_type=\"markdown\").load_data(\"../data/Q1-2023-Amazon-Earnings-Release.pdf\") #A\n",
    "def get_page_nodes(docs, separator=\"\\n---\\n\"): #B\n",
    "    \"\"\"Split each document into page node, by separator.\"\"\"\n",
    "    nodes = [] #C\n",
    "    for doc in docs:\n",
    "        doc_chunks = doc.text.split(separator)\n",
    "        for doc_chunk in doc_chunks:\n",
    "            node = TextNode(\n",
    "                text=doc_chunk,\n",
    "                metadata=deepcopy(doc.metadata),\n",
    "            )\n",
    "            nodes.append(node)\n",
    "\n",
    "    return nodes\n",
    "\n",
    "\n",
    "nodes_lp = get_page_nodes(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbb255e1-ea45-4b4d-9b80-235a1906ec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AMAZON.COM, INC.\n",
      "\n",
      "| |Consolidated Statements of Comprehensive Income (Loss)| |\n",
      "|---|---|---|\n",
      "| |(in millions)| |\n",
      "| |(unaudited)| |\n",
      "| |Three Months Ended| |\n",
      "| |March 31,| |\n",
      "| |2022|2023|\n",
      "|Net income (loss)|$ (3,844)|$ 3,172|\n",
      "|Other comprehensive income (loss):| | |\n",
      "|Foreign currency translation adjustments, net of tax of $(16) and $(10)|(333)|386|\n",
      "|Net change in unrealized gains (losses) on available-for-sale debt securities:| | |\n",
      "|Unrealized gains (losses), net of tax of $1 and $(29)|(662)|95|\n",
      "|Reclassification adjustment for losses (gains) included in “Other income (expense), net,” net of tax of $0 and $(10)|6|33|\n",
      "|Net unrealized gains (losses) on available-for-sale debt securities|(656)|128|\n",
      "|Total other comprehensive income (loss)|(989)|514|\n",
      "|Comprehensive income (loss)|$ (4,833)|$ 3,686|\n"
     ]
    }
   ],
   "source": [
    "print(nodes_lp[8].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a354ad-2f1d-4424-9b0e-95c74892c172",
   "metadata": {},
   "source": [
    "# Embeddings and vector databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a71ebc1-3200-43bc-89e7-0b397ccdadaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ······················································\n"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "os.environ[\"QDRANT_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4163e80f-e878-4dbb-b56e-2c3a4eac52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ···········································································\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"QDRANT_URL\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b1d2854a-1797-42a2-be40-adaa76a40076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499fee4-e535-4471-aa07-cddda0beedf2",
   "metadata": {},
   "source": [
    "## Adding docs to qdrant doc store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39558ece-9954-43e6-9d1b-64648fb8e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(\n",
    "    # you can use :memory: mode for fast and light-weight experiments,\n",
    "    # it does not require to have Qdrant deployed anywhere\n",
    "    # but requires qdrant-client >= 1.1.1\n",
    "    # location=\":memory:\"\n",
    "    # otherwise set Qdrant instance address with:\n",
    "    url=os.environ[\"QDRANT_URL\"],\n",
    "    # otherwise set Qdrant instance with host and port:\n",
    "    # host=\"localhost\",\n",
    "    # port=6333\n",
    "    # set API KEY for Qdrant Cloud\n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    "    # path=\"./db/\"\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"01_Basic_RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52b41205-5b47-43a7-9626-96061a81b354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72577668-c09a-4e8a-a26d-14e8c9230295',\n",
       " '85adb0a4-f74d-40d0-b2b7-ecfd362a1198',\n",
       " '985c14f4-a3a8-4de3-8b29-3a88c5b1ba7e',\n",
       " '2686627b-76c1-4465-af04-75574afb8742',\n",
       " 'dafca643-32a8-4021-b181-9a2a6dd0b0d5',\n",
       " '8294c379-2732-48c4-9fa4-a2ec649a77eb',\n",
       " '925d581e-a1dc-46e0-afca-614b3d4ec773',\n",
       " '21c56d67-956e-464b-a560-728b3cd8a5bc',\n",
       " '4773975b-2853-49ef-93b3-16298d1c846d',\n",
       " '5e69a5e9-2784-43b2-8731-62ad0e51bbfd',\n",
       " '62a3f80a-9eb7-41a7-9ed8-7d77df0b2260',\n",
       " 'a80f53e3-7884-413a-a0c3-cafafff89a75',\n",
       " 'a5f45c2b-7ccd-4c6b-afd7-882c835d72f8',\n",
       " '9985448a-0cc2-4f5c-b68d-53b4f2861c82',\n",
       " '4b6adec0-e6fe-4978-a093-7d1a5bcc7224']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding\n",
    "vector_store.add(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a923c8c5-7490-4f83-b07f-493e41566156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a5eb63cd-5c8a-46df-bde6-25e09f14c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(client=client, collection_name=\"01_Basic_RAG\")\n",
    "\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "query_engine_1 = index.as_query_engine(similarity_top_k = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0005d195-5d60-472f-ab13-e58f3ca1984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"What was the Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022?\"\"\"\n",
    "response = query_engine_1.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "db1acb52-8b80-4023-af72-37506f112d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022, was $(4,833) million.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b10ac901-496e-4197-86ce-026cbde32969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMAZON.COM, INC.\n",
      "Consolidated Statements of Comprehensive Income (Loss)\n",
      "(in millions)\n",
      "(unaudited)\n",
      "  \n",
      "Three Months Ended\n",
      "March 31,\n",
      " \n",
      "2022\n",
      "2023\n",
      "Net income (loss)\n",
      "$ \n",
      "(3,844) $ \n",
      "3,172 \n",
      "Other comprehensive income (loss):\n",
      "Foreign currency translation adjustments, net of tax of $(16) and $(10)\n",
      " \n",
      "(333)  \n",
      "386 \n",
      "Net change in unrealized gains (losses) on available-for-sale debt securities:\n",
      "Unrealized gains (losses), net of tax of $1 and $(29)\n",
      " \n",
      "(662)  \n",
      "95 \n",
      "Reclassification adjustment for losses (gains) included in “Other income (expense), \n",
      "net,” net of tax of $0 and $(10)\n",
      " \n",
      "6  \n",
      "33 \n",
      "Net unrealized gains (losses) on available-for-sale debt securities\n",
      " \n",
      "(656)  \n",
      "128 \n",
      "Total other comprehensive income (loss)\n",
      " \n",
      "(989)  \n",
      "514 \n",
      "Comprehensive income (loss)\n",
      "$ \n",
      "(4,833) $ \n",
      "3,686\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472de25-59a9-4be3-931a-18d7c3ee1689",
   "metadata": {},
   "source": [
    "## Adding llamaparse extracted docs to qdrant vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f87843f-d463-485d-afad-9f155850a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_lp = QdrantVectorStore(client=client, collection_name=\"02_Basic_RAG_lp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c485d3e2-c3b3-4cd8-84bb-0c67e938e969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['761df793-b132-4c5b-b4d1-8ac613c41822',\n",
       " '99627c25-1c97-40c4-8f0b-34ec30b9768e',\n",
       " '94395e16-f46e-4d78-9869-c1b5bfc0d61a',\n",
       " '49187c66-6df9-4460-ba24-91e493793cc2',\n",
       " 'b02c8a98-fe87-4d9c-b085-25f99ff05c1c',\n",
       " 'deb79c2b-b02d-49ba-a8d3-f7c5e8140d49',\n",
       " '538ad7de-e9c4-45aa-96af-b5f42f4560be',\n",
       " '1ffe7812-5a71-474d-a753-4d1c34ca7d5c',\n",
       " '480512a2-5af9-4e30-8fea-fe40a751c6d2',\n",
       " '9196a8e5-cb5b-4aa9-9441-992271ad6b8d',\n",
       " '574b4d94-7e51-42ec-98c2-61993508dd41',\n",
       " 'cf98e131-ab44-4737-8383-529a56e40885',\n",
       " '73c3dfe2-1ec6-4e4f-8956-887baf6e238d',\n",
       " '676af2e2-b8c0-4bae-b149-837f44d03943',\n",
       " '84b86136-fa35-4fe6-ba92-a3f54e2275aa']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for node in nodes_lp:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding\n",
    "vector_store_lp.add(nodes_lp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "90347920-2a9f-4a2b-a9ca-8d45ab224d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_lp = QdrantVectorStore(client=client, collection_name=\"02_Basic_RAG_lp\")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store_lp)\n",
    "query_engine_2 = index.as_query_engine(similarity_top_k = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0a42cbdc-c500-41f5-9403-baa04ea69cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"What was the Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022?\"\"\"\n",
    "response = query_engine_2.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c35e22a0-6bc7-4104-b7f8-8bcde15aff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022, was $ (4,833) million.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "482e7848-af44-4b86-a3cd-9b4ce83c9274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AMAZON.COM, INC.\n",
      "\n",
      "| |Consolidated Statements of Comprehensive Income (Loss)| |\n",
      "|---|---|---|\n",
      "| |(in millions)| |\n",
      "| |(unaudited)| |\n",
      "| |Three Months Ended| |\n",
      "| |March 31,| |\n",
      "| |2022|2023|\n",
      "|Net income (loss)|$ (3,844)|$ 3,172|\n",
      "|Other comprehensive income (loss):| | |\n",
      "|Foreign currency translation adjustments, net of tax of $(16) and $(10)|(333)|386|\n",
      "|Net change in unrealized gains (losses) on available-for-sale debt securities:| | |\n",
      "|Unrealized gains (losses), net of tax of $1 and $(29)|(662)|95|\n",
      "|Reclassification adjustment for losses (gains) included in “Other income (expense), net,” net of tax of $0 and $(10)|6|33|\n",
      "|Net unrealized gains (losses) on available-for-sale debt securities|(656)|128|\n",
      "|Total other comprehensive income (loss)|(989)|514|\n",
      "|Comprehensive income (loss)|$ (4,833)|$ 3,686|\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62adfb12-0231-4ad9-aebc-f7f52829b613",
   "metadata": {},
   "source": [
    "# Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "21bd6e36-180f-4da9-aa0f-030cea230a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import LLMRerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6a119fbc-2748-4952-8b86-f52d6e32a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_3 = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    node_postprocessors=[\n",
    "        LLMRerank(\n",
    "            choice_batch_size=15,\n",
    "            top_n=3,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3256526d-6444-4059-8d33-cd58dace70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine_3.query(\n",
    "    \"What was the Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a2923edf-6e2c-4013-99c4-f4f93724b233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022, was $ (4,833) million.'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "90475267-1384-4ddc-9b77-fe3dd8852944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMAZON.COM, INC.\n",
      "Consolidated Statements of Comprehensive Income (Loss)\n",
      "(in millions)\n",
      "(unaudited)\n",
      "  \n",
      "Three Months Ended\n",
      "March 31,\n",
      " \n",
      "2022\n",
      "2023\n",
      "Net income (loss)\n",
      "$ \n",
      "(3,844) $ \n",
      "3,172 \n",
      "Other comprehensive income (loss):\n",
      "Foreign currency translation adjustments, net of tax of $(16) and $(10)\n",
      " \n",
      "(333)  \n",
      "386 \n",
      "Net change in unrealized gains (losses) on available-for-sale debt securities:\n",
      "Unrealized gains (losses), net of tax of $1 and $(29)\n",
      " \n",
      "(662)  \n",
      "95 \n",
      "Reclassification adjustment for losses (gains) included in “Other income (expense), \n",
      "net,” net of tax of $0 and $(10)\n",
      " \n",
      "6  \n",
      "33 \n",
      "Net unrealized gains (losses) on available-for-sale debt securities\n",
      " \n",
      "(656)  \n",
      "128 \n",
      "Total other comprehensive income (loss)\n",
      " \n",
      "(989)  \n",
      "514 \n",
      "Comprehensive income (loss)\n",
      "$ \n",
      "(4,833) $ \n",
      "3,686\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04528cd5-19a0-490f-9870-50be9a5d08b6",
   "metadata": {},
   "source": [
    "# Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cd37e0e0-10c3-4dc6-8a60-dd7420ebbfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516e14bd424349e4aaedf71f996c3c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44536ed03c98419e969a3e732a8efc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(client=client, collection_name=\"04_Hybrid_search_1\",enable_hybrid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1685abaf-33bc-424d-b24d-08071501ad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72577668-c09a-4e8a-a26d-14e8c9230295',\n",
       " '85adb0a4-f74d-40d0-b2b7-ecfd362a1198',\n",
       " '985c14f4-a3a8-4de3-8b29-3a88c5b1ba7e',\n",
       " '2686627b-76c1-4465-af04-75574afb8742',\n",
       " 'dafca643-32a8-4021-b181-9a2a6dd0b0d5',\n",
       " '8294c379-2732-48c4-9fa4-a2ec649a77eb',\n",
       " '925d581e-a1dc-46e0-afca-614b3d4ec773',\n",
       " '21c56d67-956e-464b-a560-728b3cd8a5bc',\n",
       " '4773975b-2853-49ef-93b3-16298d1c846d',\n",
       " '5e69a5e9-2784-43b2-8731-62ad0e51bbfd',\n",
       " '62a3f80a-9eb7-41a7-9ed8-7d77df0b2260',\n",
       " 'a80f53e3-7884-413a-a0c3-cafafff89a75',\n",
       " 'a5f45c2b-7ccd-4c6b-afd7-882c835d72f8',\n",
       " '9985448a-0cc2-4f5c-b68d-53b4f2861c82',\n",
       " '4b6adec0-e6fe-4978-a093-7d1a5bcc7224']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4d074aff-3159-46d3-93c1-924a830fefea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27df6d0d0664e91a12c5ae4923eb432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8917b3b93545b88a04e92dc27d8fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022, was $(4,833) million.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(client=client, collection_name=\"04_Hybrid_search_1\",enable_hybrid=True)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "query_engine_4 = index.as_query_engine(similarity_top_k = 5, vector_store_query_mode=\"hybrid\")\n",
    "query = \"\"\"What was the Comprehensive income (loss) for Amazon for the Three Months Ended March 31, 2022?\"\"\"\n",
    "response = query_engine_4.query(query)\n",
    "str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b4488-b447-48d2-beb0-91c88565e038",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12b6f58b-2523-42eb-b074-22cccda9c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79916163-69ea-4e31-9f94-f6dede4dec2b",
   "metadata": {},
   "source": [
    "## ground truth evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3995bb94-e156-4a3b-94f0-e57ceb8150cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evals = json.load(\"gt-aws-q1-2023.json\")\n",
    "f = open(\"gt-aws-q1-2023.json\")\n",
    "\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data_eval = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "add09ba5-b9ee-437f-a9f1-072e062daedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61d73310-b75e-4cd8-b006-f951e6971146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate, PromptTemplate\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "425ea177-235d-47e5-a8b6-a46ffd41671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTNESS_SYS_TMPL = \"\"\"\n",
    "You are an expert evaluation system for a financial document q&a tool.\n",
    "\n",
    "You are given the following information:\n",
    "- a user query, \n",
    "- a reference answer, and\n",
    "- a generated answer.\n",
    "\n",
    "Your job is to judge the correctness of the generated answer.\n",
    "Output a score that represents if the answer is correct (1) or wrong (0).\n",
    "\n",
    "If the generated answer is basically the same (e.g. if the reference answer is 54,330 million whereas the generated answer is 54 billion,\n",
    "give a score of 1. Only give 0 if the answer is completely wrong.)\n",
    "\n",
    "But if the answer is completely wrong (e.g. reference answer is 21 million, but generated answer is 54 billion, give 0.)\n",
    "\n",
    "You must return your response in a line with only the score.\n",
    "Do not return answers in any other format.\n",
    "On a separate line provide your reasoning for the score as well.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "CORRECTNESS_USER_TMPL = \"\"\"\n",
    "## User Query\n",
    "{query}\n",
    "\n",
    "## Reference Answer\n",
    "{reference_answer}\n",
    "\n",
    "## Generated Answer\n",
    "{generated_answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3235138d-1d84-4923-ab26-f81bb49861bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "eval_chat_template = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.SYSTEM, content=CORRECTNESS_SYS_TMPL),\n",
    "        ChatMessage(role=MessageRole.USER, content=CORRECTNESS_USER_TMPL),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de27adc8-ebc9-47b2-8e31-ab9df67392d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_correctness_eval(\n",
    "    query_str: str,\n",
    "    reference_answer: str,\n",
    "    generated_answer: str,\n",
    "    llm: OpenAI,\n",
    "    threshold: float = 0.0,\n",
    ") -> Dict:\n",
    "    \"\"\"Run correctness eval.\"\"\"\n",
    "    fmt_messages = eval_chat_template.format_messages(\n",
    "        llm=llm,\n",
    "        query=query_str,\n",
    "        reference_answer=reference_answer,\n",
    "        generated_answer=generated_answer,\n",
    "    )\n",
    "    chat_response = llm.chat(fmt_messages)\n",
    "    raw_output = chat_response.message.content\n",
    "\n",
    "    # Extract from response\n",
    "    score_str, reasoning_str = raw_output.split(\"\\n\", 1)\n",
    "    score = float(score_str)\n",
    "    reasoning = reasoning_str.lstrip(\"\\n\")\n",
    "\n",
    "    return {\"score\": score, \"reason\": reasoning}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6cd3d816-0bcc-493f-9a20-f812a54d63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = data_eval[0]['question']\n",
    "reference_answer = data_eval[0]['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f83323f0-c56a-42f3-a79a-ad1ba37cf894",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = data_eval[0]['question']\n",
    "reference_answer = data_eval[0]['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2a82d1a9-ab4b-4069-a701-003a469093b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine_1.query(query)\n",
    "generated_answer = str(response)\n",
    "context = \" \".join([node.dict()['node']['text'] for node in response.source_nodes])\n",
    "#print(generated_answer,context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0c653687-ba3f-4936-886b-b5bdb348c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.0,\n",
       " 'reason': \"The generated answer is correct. The reference answer states that Amazon's operating cash flow for the trailing twelve months (TTM) in Q1 2023 was $54,330 million, which is equivalent to $54.3 billion as stated in the generated answer.\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = run_correctness_eval(\n",
    "    query, reference_answer, generated_answer, llm=llm, threshold=4.0\n",
    ")\n",
    "display(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "22416423-de6f-4ec6-a8f1-ce393ba73db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping!\n",
    "# score_1=[]\n",
    "# reason_1=[]\n",
    "# context_1=[]\n",
    "# ans_1=[]\n",
    "\n",
    "# score_2=[]\n",
    "# reason_2=[]\n",
    "# ans_2=[]\n",
    "# context_2=[]\n",
    "\n",
    "score_3=[]\n",
    "reason_3=[]\n",
    "ans_3=[]\n",
    "context_3=[]\n",
    "\n",
    "# score_4=[]\n",
    "# reason_4=[]\n",
    "# ans_4=[]\n",
    "# context_4=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a45963de-0036-4382-8014-c4c3beb931a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "#looping!\n",
    "for i in range(0,len(data_eval)):\n",
    "    query = data_eval[i]['question']\n",
    "    reference_answer = data_eval[i]['answer']\n",
    "#     response = query_engine_1.query(query) #basic RAG\n",
    "#     generated_answer = str(response)\n",
    "#     context = \" \".join([node.dict()['node']['text'] for node in response.source_nodes])\n",
    "#     ans_1.append(generated_answer)\n",
    "#     context_1.append(context)\n",
    "\n",
    "#     eval_results = run_correctness_eval(\n",
    "#         query, reference_answer, generated_answer, llm=llm, threshold=1.0\n",
    "#     )\n",
    "\n",
    "#     score_1.append(eval_results['score'])\n",
    "#     reason_1.append(eval_results['reason'])\n",
    "\n",
    "#     response = query_engine_2.query(query) #llamaparse extraction\n",
    "#     generated_answer = str(response)\n",
    "#     context = \" \".join([node.dict()['node']['text'] for node in response.source_nodes])\n",
    "#     ans_2.append(generated_answer)\n",
    "#     context_2.append(context)\n",
    "\n",
    "\n",
    "#     eval_results = run_correctness_eval(\n",
    "#         query, reference_answer, generated_answer, llm=llm, threshold=1.0\n",
    "#     )\n",
    "\n",
    "#     score_2.append(eval_results['score'])\n",
    "#     reason_2.append(eval_results['reason'])    \n",
    "    \n",
    "    \n",
    "    response = query_engine_3.query(query) #re-ranker RAG\n",
    "    generated_answer = str(response)\n",
    "    context = \" \".join([node.dict()['node']['text'] for node in response.source_nodes])\n",
    "    ans_3.append(generated_answer)\n",
    "    context_3.append(context)\n",
    "\n",
    "\n",
    "    eval_results = run_correctness_eval(\n",
    "        query, reference_answer, generated_answer, llm=llm, threshold=1.0\n",
    "    )\n",
    "\n",
    "    score_3.append(eval_results['score'])\n",
    "    reason_3.append(eval_results['reason'])\n",
    "\n",
    "#     response = query_engine_4.query(query) #hybrid RAG\n",
    "#     generated_answer = str(response)\n",
    "#     context = \" \".join([node.dict()['node']['text'] for node in response.source_nodes])\n",
    "#     ans_4.append(generated_answer)\n",
    "#     context_4.append(context)\n",
    "\n",
    "\n",
    "#     eval_results = run_correctness_eval(\n",
    "#         query, reference_answer, generated_answer, llm=llm, threshold=1.0\n",
    "#     )\n",
    "\n",
    "#     score_4.append(eval_results['score'])\n",
    "#     reason_4.append(eval_results['reason'])     \n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fada6c65-5700-418d-90ca-89532ccde3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b58e88ba-587a-4c24-ac00-9f8a9ae5bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame([score_1,reason_1,ans_1,context_1,\n",
    "                 score_2,reason_2,ans_2,context_2,\n",
    "                 score_3,reason_3,ans_3,context_3,\n",
    "                 score_4,reason_4,ans_4,context_4]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "faa774ef-0285-4968-b7fd-f6bf28bbcc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['score_1','reason_1','ans_1','context_1',\n",
    "              'score_2','reason_2','ans_2','context_2',\n",
    "              'score_3','reason_3','ans_3','context_3',\n",
    "              'score_4','reason_4','ans_4','context_4']\n",
    "df['reference_answer'] = [d['answer'] for d in data_eval]\n",
    "df['question'] = [d['question'] for d in data_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "96d69a58-4133-4aac-a33e-cd3a925882fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('eval_ch3_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a11a409a-0b78-41e4-bb06-5a940724dda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157894736842105 0.7456140350877193 0.7894736842105263 0.8736842105263157\n"
     ]
    }
   ],
   "source": [
    "print(np.array(score_1,dtype=float).mean(),np.array(score_2,dtype=float).mean(),np.array(score_3,dtype=float).mean(),np.array(score_4,dtype=float).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4661d5-5717-48a6-b917-6730616a52e8",
   "metadata": {},
   "source": [
    "# Eval using deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "21d798cf-5e6b-4fc2-8a5e-9d2b7b3b7104",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4100\\3353087881.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFaithfulnessMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#from deepeval.test_case import LLMTestCase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msend_feedback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massert_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_run\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mon_test_run_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\event\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfeedback\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msend_feedback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\event\\event.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mApi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEndpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprocess_hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m from deepeval.event.api import (\n\u001b[0;32m      6\u001b[0m     \u001b[0mAPIEvent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\test_run\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from .test_run import (\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mTestRun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_run_manager\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mTEMP_FILE_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mLLMApiTestCase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\test_run\\test_run.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrich\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mApi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEndpoints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m from deepeval.test_run.api import (\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\metrics\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase_metric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseMetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseConversationalMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBiasMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtoxicity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoxicity\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mToxicityMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhallucination\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhallucination\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHallucinationMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\metrics\\bias\\bias.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mConversationalTestCase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindicator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetric_progress_indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeepEvalBaseLLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_or_create_event_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprettify_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\metrics\\indicator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCachedTestCase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtelemetry\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcapture_metric_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepeval\\telemetry.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopentelemetry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTracerProvider\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopentelemetry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msdk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchSpanProcessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import (\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mOTLPSpanExporter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\trace_exporter\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mencode_spans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m )\n\u001b[1;32m---> 27\u001b[1;33m from opentelemetry.exporter.otlp.proto.grpc.exporter import (\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mOTLPExporterMixin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0m_get_credentials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0m_create_exp_backoff_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m )\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_details_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRetryInfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m from grpc import (\n\u001b[0;32m     45\u001b[0m     \u001b[0mChannelCredentials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\google\\rpc\\error_details_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mcontaining_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     fields=[\n\u001b[1;32m---> 50\u001b[1;33m         _descriptor.FieldDescriptor(\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"retry_delay\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mfull_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"google.rpc.RetryInfo.retry_delay\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\skand\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\google\\protobuf\\descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    619\u001b[0m     \"\"\"Whether the field distinguishes between unpopulated and default values.\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m     \u001b[0mRaises\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msingular\u001b[0m \u001b[0mfield\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlinked\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0mnor\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     \"\"\"\n",
      "\u001b[1;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from deepeval.metrics import FaithfulnessMetric\n",
    "#from deepeval.test_case import LLMTestCase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b1dd3-4171-471e-b2f7-20f7592907c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = FaithfulnessMetric(\n",
    "threshold=0.7,\n",
    "model=\"gpt-4\",\n",
    "include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "input=user_query,\n",
    "actual_output=final_answer_original,\n",
    "retrieval_context=formatted_top_results_original\n",
    ")\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
